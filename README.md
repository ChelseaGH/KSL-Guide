# KSL-Guide
## KSL-Guide is a large-scale Korean Sign Language (KSL) dataset which includes interrogative sentences for guiding the Deaf and hard-of-hearing.

<img align="center" src="https://user-images.githubusercontent.com/25498950/147634121-15593a39-cabc-4fa5-96c4-be5053a66cdb.jpg">


We introduce a new publicly available large-scale Korean Sign Language (KSL) dataset—KSL-Guide—that includes both declarative sentences and comparable interrogative sentences, which are required for a model to achieve high performance in real-world interactive tasks deployed on service applications. Our dataset contains a total of 121K sign language video samples featuring sentences and words spoken by native KSL speakers with extensive annotations (e.g., gloss, translation, 2D/3D human pose keypoints, and timestamps). We exploit a multi-camera system to produce 3D human pose keypoints as well as 2D keypoints from multi-view RGB. We have demonstrated the advantage of having a considerable number of interrogative sentences in a dataset, which allows high performance of recognition/translation tasks, and facilitates interactive communication between Deaf and hearing people in the community.


## Dataset
[Intro](https://aihub.or.kr/aidata/7965)


[Download](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=103)


## Contacts
smham@kaist.ac.kr
<!--## To do-->

## Publications
Our paper is available in the FG Conference Proceedings.
```
@InProceedings{Ham21,
  author       = "Soomin Ham and Kibaek Park and YeongJun Jang and Youngtaek Oh and Seokmin Yun and Sukwon Yoon and Chango Jo Kim and Han-Mu Park and In So Kweon",
  title        = "KSL-Guide: A Large-scale Korean Sign Language Dataset Including Interrogative Sentences for Guiding the Deaf and Hard-of-Hearing",
  booktitle    = "IEEE International Conference on Automatic Face and Gesture Recognition",
  year         = "2021",
}
```
